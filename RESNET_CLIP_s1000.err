[rank: 0] Global seed set to 1000
Some weights of the model checkpoint at microsoft/BiomedVLP-CXR-BERT-general were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Using 16bit None Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
[rank: 0] Global seed set to 1000
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name           | Type               | Params
------------------------------------------------------
0 | img_backbone   | resnet_model       | 23.5 M
1 | img_projector  | ProjectionHeadCLIP | 1.3 M 
2 | mm_criterion   | CLIP_Loss          | 0     
3 | text_backbone  | bert_model         | 109 M 
4 | text_projector | ProjectionHeadCLIP | 657 K 
------------------------------------------------------
134 M     Trainable params
0         Non-trainable params
134 M     Total params
269.921   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Epoch 0, global step 1187: 'val_loss' reached 3.83748 (best 3.83748), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=0-step=1187-v1.ckpt' as top 1
Epoch 1, global step 2374: 'val_loss' reached 3.70173 (best 3.70173), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=1-step=2374.ckpt' as top 1
Epoch 2, global step 3561: 'val_loss' reached 3.62022 (best 3.62022), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=2-step=3561.ckpt' as top 1
Epoch 3, global step 4748: 'val_loss' reached 3.60540 (best 3.60540), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=3-step=4748.ckpt' as top 1
Epoch 4, global step 5935: 'val_loss' reached 3.58579 (best 3.58579), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=4-step=5935.ckpt' as top 1
Epoch 5, global step 7122: 'val_loss' reached 3.55660 (best 3.55660), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=5-step=7122.ckpt' as top 1
Epoch 6, global step 8309: 'val_loss' reached 3.54111 (best 3.54111), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=6-step=8309.ckpt' as top 1
Epoch 7, global step 9496: 'val_loss' was not in top 1
Epoch 8, global step 10683: 'val_loss' reached 3.46125 (best 3.46125), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=8-step=10683.ckpt' as top 1
Epoch 9, global step 11870: 'val_loss' reached 3.42062 (best 3.42062), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=9-step=11870.ckpt' as top 1
Epoch 10, global step 13057: 'val_loss' reached 3.37744 (best 3.37744), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=10-step=13057.ckpt' as top 1
Epoch 11, global step 14244: 'val_loss' reached 3.33925 (best 3.33925), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=11-step=14244.ckpt' as top 1
Epoch 12, global step 15431: 'val_loss' reached 3.32823 (best 3.32823), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=12-step=15431.ckpt' as top 1
Epoch 13, global step 16618: 'val_loss' was not in top 1
Epoch 14, global step 17805: 'val_loss' was not in top 1
Epoch 15, global step 18992: 'val_loss' reached 3.29586 (best 3.29586), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=15-step=18992.ckpt' as top 1
Epoch 16, global step 20179: 'val_loss' was not in top 1
Epoch 17, global step 21366: 'val_loss' reached 3.26403 (best 3.26403), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=17-step=21366.ckpt' as top 1
Epoch 18, global step 22553: 'val_loss' was not in top 1
Epoch 19, global step 23740: 'val_loss' reached 3.24797 (best 3.24797), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=19-step=23740.ckpt' as top 1
Epoch 20, global step 24927: 'val_loss' reached 3.23915 (best 3.23915), saving model to '/gpfs/data/denizlab/Users/hh2740/MIMICCXR-MutliModal-SelfSupervision/model_saved/epoch=20-step=24927.ckpt' as top 1
Epoch 21, global step 26114: 'val_loss' was not in top 1
Epoch 22, global step 27301: 'val_loss' was not in top 1
Epoch 23, global step 28488: 'val_loss' was not in top 1
Epoch 24, global step 29675: 'val_loss' was not in top 1
Epoch 25, global step 30862: 'val_loss' was not in top 1
